{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Kuka","text":"<p>Kuka is a Python library designed to support exploratory data analysis (EDA), data modeling, and interpretation of machine learning models.  </p> <p>Its main goal is to serve as a practical reference toolkit throughout the various stages of a machine learning pipeline.</p> <p>While major libraries like <code>scikit-learn</code>, <code>pandas</code>, and <code>matplotlib</code> offer robust general-purpose tools, Kuka fills the gaps by providing streamlined and customized utilities for tasks that are commonly needed but not readily available out-of-the-box.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Simplified tools for data exploration and visualization  </li> <li>Utilities for model interpretation and diagnostics  </li> <li>Automation-friendly interfaces for analysis workflows</li> </ul> <p>The API is organized based on 4 of the 5 classical stages of a typical ML application:</p> <p></p> <ol> <li>Exploratory Data Analysis (EDA)  </li> <li>Feature Engineering and Modeling  </li> <li>Model Training and Evaluation  </li> <li>Interpretation and Visualization  </li> </ol> <p>\ud83d\udccc Note: This library is in active development and aims to evolve with practical needs from real-world ML projects.</p>"},{"location":"#built-with","title":"Built With","text":"<ul> <li><code>pandas</code> </li> <li><code>numpy</code> </li> <li><code>matplotlib</code> </li> <li><code>scipy</code> </li> <li><code>scikit-learn</code> </li> <li><code>seaborn</code></li> </ul>"},{"location":"api_reference/0_utils/","title":"_Utilities","text":"Utilities for coding"},{"location":"api_reference/0_utils/#_input_function_validation","title":"_input_function_validation","text":"<pre><code>decorator utils._input_function_validation()\n</code></pre> <p>Decorator with input arguments.</p> <p>A decorator used to validate function inputs using a user-defined validation protocol. It ensures input types and values match the expected constraints prior to executing the target function.</p> <p>Parameters:</p> <ul> <li><code>_input_val_dict</code>: dict</li> </ul> <p>Dictionary that will carry the entire validation protocol and must be like:</p> <pre><code>_input_type_dict = {\n    'variable_name1': ( var_type-&gt;(str, list, tuple), validation_mode-&gt;str, validation_parameters ),\n    'variable_name2': ( var_type-&gt;(str, list, tuple), validation_mode-&gt;str, validation_parameters ),\n    ...\n    }\n</code></pre> <p>The <code>variable_name</code> key must be a string and its value must be a list or tuple. If theres no type constraint for a variable, use <code>object</code> as the type.</p> <p>The variable <code>validation_mode</code> and respective <code>validation_parameters</code> can have the values of:</p> <ul> <li><code>None or 'none'</code>: There is no restriction on the parameter value.<ul> <li><code>validation_parameters</code> = Anything. Will not be read. Can be occulted.</li> </ul> </li> <li><code>'pattern'</code>: The parameter value must be exactly one of a list of values.</li> <li><code>validation_parameters</code> = A list/tuple of exact valid values. Ex: <code>['a', 'b', 'c'] or [1, 3, 5, 6] or ['a', 3, {'a':1}]</code>.</li> <li><code>'range'</code>: The parameter value has minimum and maximum values. It only works with numeric parameters.<ul> <li><code>validation_parameters</code> = A list/tuple with the format <code>[min, max]</code>. <code>np.inf</code> can be used.</li> </ul> </li> <li><code>'length'</code>: The parameter is a list, tuple or string with a given length.<ul> <li><code>validation_parameters</code> = Int. Length of the tuple/list. The <code>len()</code> function is applied.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>none</code></li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: If <code>_input_val_dict</code> is malformed or contains invalid configuration.</li> <li><code>AssertionError</code>: If an input value does not match the expected type or fails the validation rules.</li> </ul> <p>Examples:</p> <pre><code>&gt; import numpy as np\n&gt; from kuka.utils import _input_function_validation\n&gt;\n&gt; _input_val_dict = {\n&gt;     'a': (str, None)\n&gt;     'b': ((list, tuple), 'length', 4)\n&gt;     'c': ((int, float), 'range', [0, 10])\n&gt;     'd': ((int, float), 'range', [5, np.inf])\n&gt;     'e': (str, 'pattern', ['opt1', 'opt2', 'opt3'])\n&gt;     }\n&gt; \n&gt; @_input_function_validation(_input_val_dict)\n&gt; def function(a, b, c=1, d=42, e='opt1'):\n&gt;     ...\n&gt;     return ...\n</code></pre>"},{"location":"api_reference/0_utils/#_is_valid_path","title":"_is_valid_path","text":"<pre><code>function utils._is_valid_path()\n</code></pre> <p>Checks whether a given string is a valid path to an EXISTING file or directory..</p> <p>Parameters:</p> <ul> <li> <p><code>path_str</code>: type, valid values</p> <p>Parameter description.</p> </li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>type_path = 'file or dir'</code>: str, \"file\" or \"dir\"</p> <p>Parameter description.</p> </li> <li> <p><code>check_only_syntax = False</code>: type, valid values</p> <p>Parameter description.</p> </li> </ul> <p>Returns: * <code>True or False</code>: bool     <code>True</code> if <code>path_str</code> is a valid and existing path of the specified type, <code>False</code> otherwise.</p> <p>Raises:</p> <ul> <li> <p><code>AssertionError</code>:</p> <p>If <code>type_path</code> string is neither a \"file\" nor a \"dir\".</p> </li> </ul> <p>Notes:</p> <p>This function validates whether <code>path_str</code> is a properly formatted string that can represent a file or directory path on the current operating system. It checks: - That it is a non-empty string - That it does not contain invalid characters (especially on Windows) - That backslashes are used correctly (e.g., allows network paths like \\\\server) - That it points to an existing file or directory, depending on <code>type_path</code></p> <p>Examples:</p> <pre><code>&gt; __is_valid_path(\"data/model.pkl\", type_path=\"file\")\n&gt; __is_valid_path(\"data/\", type_path=\"dir\")\n</code></pre>"},{"location":"api_reference/0_utils/#plot","title":"plot","text":""},{"location":"api_reference/0_utils/#_adjust_obj_to_ref","title":"_adjust_obj_to_ref","text":"<pre><code>function utils.plot._adjust_obj_to_ref()\n</code></pre> <p>Automatically adjusts matplotlib text-like objects to avoid overlap or excessive size compared to reference elements. Applies a sequence of correction steps like rotation, font size scaling, abbreviation, repositioning, or text wrapping to make labels or texts fit within the visual bounds of a figure.</p> <p>Parameters</p> <ul> <li> <p><code>fig</code> (<code>matplotlib.figure.Figure</code>):     The figure containing the objects to be adjusted. Used to calculate bounding boxes.</p> </li> <li> <p><code>obj_list</code> (<code>list</code>):     List of matplotlib objects to be adjusted. Objects must implement <code>.get_window_extent()</code>.</p> </li> </ul> <pre><code>    Ex: \n    list(text_list) = [Text(), Text(), Text(), ...]\n    list(ax.texts), ax.get_xticklabels()\n</code></pre> <ul> <li> <p><code>ref_list</code> (<code>list</code>):     List of reference elements used to compare dimensions or check overlap. Ex.: <code>[ax]</code>.</p> </li> <li> <p><code>dimension</code> (<code>str</code>):     Direction of dimensional constraint: <code>'w'</code> for width or <code>'h'</code> for height.</p> </li> <li> <p><code>steps</code> (<code>list</code> of <code>str</code>):     Sequence of adjustment strategies to attempt, in order. Available options:</p> <ul> <li><code>'try_rotate'</code>: Rotate text incrementally. Has \"get_rotation()\" and \"set_rotation()\" methods;</li> <li><code>'decrease_fontsize'</code>: Scale down font size. Has \"get_fontsize()\" and \"set_fontsize()\" methods;</li> <li><code>'reset_fontsize'</code>: Restore original font size. Has \"set_fontsize()\" method;</li> <li><code>'remove_label'</code>: Remove all labels/texts. Has \"set_text()\" method;</li> <li><code>'abbreviate_or_remove_tick_labels'</code>: Replace tick labels with abbreviated symbols. Is a \"ax.get_xticklabels()\" or \"ax.get_yticklabels()\" matplotlib object. works only if the ticklabels obey the common position for their respective axes. (x, 0) for the x_axis and (0, y) for the y_axis;</li> <li><code>'abbreviate_or_remove'</code>: Replace text content with abbreviations or remove them. Has \".get_text()\", \"set_text()\" and \".get_position()\" method;</li> <li><code>'move_until_no_overlaps'</code>: Move objects until no overlap is detected. Has \".set_position()\" method;</li> <li><code>'wrap_until_fit'</code>: Wrap long text into multiple lines. Has \".get_text()\" and \".set_text()\" methods.</li> </ul> </li> </ul> <p>Default Parameters</p> <ul> <li> <p><code>threshold = 0.8</code> (<code>float</code>):     Fraction of total space occupied by <code>obj_list</code> relative to <code>ref_list</code> before adjustments are applied.</p> </li> <li> <p><code>rotate_max = 90</code> (<code>float</code>):     Maximum rotation angle (degrees) for <code>'try_rotate'</code> step.</p> </li> <li> <p><code>rotate_rate = 5</code> (<code>float</code>):     Incremental rotation applied per attempt in <code>'try_rotate'</code>.</p> </li> <li> <p><code>fontsize_max = 7.</code> (<code>float</code>):     Threshold under which font size will not be decreased.</p> </li> <li> <p><code>fontsize_rate = 0.9</code> (<code>float</code>):     Multiplicative factor to reduce font size during <code>'decrease_fontsize'</code>.</p> </li> <li> <p><code>abbreviate_list = ['letters']</code> (<code>list</code> or <code>tuple</code>):     Custom abbreviations to use in abbreviation steps. Defaults to letter-based abbreviations.</p> </li> <li> <p><code>tick_ax = None</code> (<code>matplotlib.axes.Axes</code> or <code>None</code>):     Axis object required for <code>'abbreviate_or_remove_tick_labels'</code> step.</p> </li> <li> <p><code>move_rate = (None, None)</code> (<code>tuple</code>):     (x, y) amount to translate objects during <code>'move_until_no_overlaps'</code>.</p> </li> <li> <p><code>wrap_rate = 2</code> (<code>int</code>):     Width decrement step used in <code>'wrap_until_fit'</code>.</p> </li> <li> <p><code>wrap_maxlines = 3</code> (<code>int</code>):     Maximum number of lines allowed in wrapped text.</p> </li> <li> <p><code>_plot_ref = False</code> (<code>bool</code>):     Whether to plot reference bounding boxes for debugging.</p> </li> <li> <p><code>_plot_obj = False</code> (<code>bool</code>):     Whether to plot object bounding boxes for debugging.</p> </li> </ul> <p>Returns - <code>None</code>:   The function operates in-place, modifying the input objects directly.</p> <p>Examples</p> <pre><code>fig, ax = plt.subplots()\nbars = ax.bar(['Very very long label A', 'Extremely long label B'], [3, 5])\nfig.canvas.draw()\nticklabels = ax.get_xticklabels()\n</code></pre> <pre><code># Rotate and shrink labels to fit\n_adjust_obj_to_ref(fig, ticklabels, bars, dimension='w',\n                   steps=['try_rotate', 'decrease_fontsize'], threshold=0.9)\n</code></pre> <pre><code># Abbreviate labels if needed\n_adjust_obj_to_ref(fig, ticklabels, bars, dimension='w',\n                   steps=['abbreviate_or_remove_tick_labels'],\n                   abbreviate_list=['A', 'B'], tick_ax=ax)\n</code></pre> <pre><code># Wrap long text into multiple lines\ntexts = [ax.text(0.5, 0.95, 'A very long title', ha='center', transform=ax.transAxes)]\n_adjust_obj_to_ref(fig, texts, [ax], dimension='w',\n                   steps=['wrap_until_fit'], wrap_rate=3, wrap_maxlines=3)\n\n</code></pre>"},{"location":"api_reference/0_utils/#_plot_bboxes","title":"_plot_bboxes","text":"<pre><code>function utils.plot._plot_bboxes()\n</code></pre> <p>Plots bounding boxes on a matplotlib figure using figure-relative coordinates (0\u20131).</p> <p>This function helps visualize and debug layout issues by drawing rectangular outlines corresponding to graphical elements such as tick labels, texts, or axes objects. It converts pixel-based bounding boxes to figure fraction coordinates and overlays them on the figure.</p> <p>Parameters:</p> <ul> <li> <p><code>bbox_list</code>: list or tuple of matplotlib.transforms.Bbox, valid values: \u2014   A list of bounding boxes to be drawn, given in pixel coordinates (usually from <code>.get_window_extent(renderer)</code>).</p> </li> <li> <p><code>fig</code>: matplotlib.figure.Figure, valid values: \u2014   The target figure on which bounding boxes will be drawn.</p> </li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>color = 'red'</code>: str, valid values: \u2014   Color of the bounding box borders.</p> </li> <li> <p><code>linewidth = 1</code>: int or float, valid values: range [0, \u221e)   Thickness of the rectangle edges.</p> </li> <li> <p><code>linestyle = '-'</code>: str    Style of the rectangle edges (e.g., '-', '--', ':', '-.').</p> </li> </ul> <p>Returns:</p> <ul> <li><code>rect_list</code>: list of matplotlib.patches.Rectangle   List of the rectangle objects added to the figure.</li> </ul> <p>Examples:</p> <pre><code>    fig, ax = plt.subplots()\n    bars = ax.bar(['A', 'B', 'C'], [5, 7, 4])\n    fig.canvas.draw()\n    renderer = fig.canvas.get_renderer()\n</code></pre> <pre><code>    bbox_list = [bar.get_window_extent(renderer) for bar in bars]\n    _plot_bboxes(bbox_list, fig, color='green', linewidth=2, linestyle='--')\n</code></pre> <pre><code>    # Also works with tick labels or text objects:\n    tick_bboxes = [label.get_window_extent(renderer) for label in ax.get_xticklabels()]\n    _plot_bboxes(tick_bboxes, fig, color='blue')\n</code></pre>"},{"location":"api_reference/0_utils/#_plot_text","title":"_plot_text","text":"<pre><code>function utils.plot._plot_text()\n</code></pre> <p>Plot a text in matplotlib. Useful to show some simple LaTeX codes.</p> <p>Parameters:</p> <ul> <li><code>text</code>: str     Text string to be plotted.</li> </ul> <p>Default Parameters:</p> <ul> <li><code>_fontsize = 12</code>: float or int, valid values: range [0, \u221e)     Font size for the plotted text.</li> </ul> <p>Returns:</p> <ul> <li>tuple of (<code>matplotlib.figure.Figure</code>, <code>matplotlib.axes.Axes</code>)     The figure and axes objects containing the plotted text.</li> </ul> <p>Example:</p> <pre><code>fig, ax = _plot_text(\"Hello World\", _fontsize=14)\nfig.show()\n</code></pre>"},{"location":"api_reference/1_eda/","title":"EDA","text":"EDA - (Exploratory Data Analysis)"},{"location":"api_reference/1_eda/#plot_columns_dist","title":"plot_columns_dist","text":"<pre><code>function plot.plot_columns_dist()\n</code></pre> <p>Plot a grid of distributions for each column in a DataFrame.</p> <p>This function automatically detects the type of each column and chooses the appropriate plot: - Numerical (float-compatible) columns are displayed using histograms. - Non-numerical (object/categorical) columns are shown as bar plots with value counts.</p> <p>It organizes all plots into a structured subplot grid, and includes automatic font size adjustments and label abbreviation to avoid label overlaps, especially for categorical variables.</p> <p>Parameters:</p> <ul> <li><code>df</code>: <code>pd.DataFrame</code>     Dataframe containing the columns to be plotted.</li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>ncols = 3</code>: <code>int</code>, valid values: range [0, \u221e)     Number of columns in the subplot grid layout.</p> </li> <li> <p><code>plotsize = plt.rcParams['figure.figsize'] * [0.5, 0.35]</code>: <code>list</code> or <code>tuple</code> (length=2), valid values: positive numbers     Base plot size (width, height) in inches for each subplot. The total figure size is scaled by (plotsize * [ncols, nrows]).</p> </li> </ul> <p>Returns:</p> <ul> <li> <p><code>fig</code>: matplotlib.figure.Figure     The generated figure.</p> </li> <li> <p><code>ax</code>: numpy.ndarray of matplotlib.axes._subplots.AxesSubplot     Array of axes corresponding to each subplot.</p> </li> </ul> <p>Examples:</p> <pre><code>from kuka.eda import plot_columns_dist\nimport seaborn as sns\n\ndf = sns.load_dataset('penguins')\n\nfig, ax = plot_columns_dist(\n    df,\n    ncols=2,\n    plotsize=[4, 3]\n)\n\nfig.show()\n</code></pre>"},{"location":"api_reference/1_eda/#plot_dist","title":"plot_dist","text":"<pre><code>function plot.plot_dist()\n</code></pre> <p>Plot the distribution of a variable using bar plots or histograms, with support for category segmentation, normalization, and extensive customization options.</p> <p>This function is useful for visually exploring the frequency distribution of a variable, optionally segmented by a categorical column (<code>by</code>). It supports different layout modes such as stacked bars, grouped bars, or separated subplots.</p> <p>Parameters </p> <ul> <li> <p><code>df</code>: <code>pandas.DataFrame</code>     Input DataFrame containing the data to be plotted.</p> </li> <li> <p><code>variable</code>: <code>str</code>     Name of the column to be plotted.</p> </li> <li> <p><code>mode</code>: <code>str</code>     Plotting mode:         - <code>'bar'</code> : for categorical variables (bar chart)         - <code>'hist'</code>: for numeric variables (histogram).</p> </li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>by = None</code>: <code>str</code> or <code>None</code>      Name of the grouping column for segmentation (used to separate or color the distributions).</p> </li> <li> <p><code>by_mode = 'stacked'</code>: <code>str</code> {'stacked', 'grouped', 'subploted'}     Layout style when grouping is applied:         - <code>'stacked'</code>   : stacked bars         - <code>'grouped'</code>   : side-by-side grouped bars         - <code>'subploted'</code> : one subplot per category</p> </li> <li> <p><code>alpha = 0.5</code>: <code>float</code>     Transparency level of the bars (from 0 to 1).</p> </li> <li> <p><code>colors_reference = ['b','g','r','c','m','y','k']</code>: <code>list</code> or <code>tuple</code>     List of colors to assign to <code>by</code> categories (used if <code>dict_colors_of_variable_by</code> is not provided).</p> </li> <li> <p><code>figsize = None</code>: <code>list</code> or <code>tuple</code> of length 2     Size of the figure in inches: <code>[width, height]</code>.</p> </li> <li> <p><code>fontsize = None</code>: <code>int</code> or <code>float</code>      Global font size for the plot.</p> </li> <li> <p><code>labels = None</code>: <code>None</code>, <code>'top'</code>, <code>'center'</code>     If not None, adds value labels to the bars:         - <code>'top'</code>    : place above the bars         - <code>'center'</code> : place inside the bars</p> </li> <li> <p><code>labels_format = None</code>: <code>str</code>     Format string for bar labels (e.g., '.0f', '.1%', etc.).</p> </li> <li> <p><code>labels_padding = [0, 0]</code>: <code>list</code> or <code>tuple</code> of length 2     Offset for labels in points: <code>[x_offset, y_offset]</code>.</p> </li> <li> <p><code>labels_threshold = 0.85</code>: <code>float</code>     Minimum proportion of overlap allowed for the label to remain visible.</p> </li> <li> <p><code>norm = None</code>: <code>bool</code>     If True, normalize bar heights so they sum to 1. Useful for comparing distributions.</p> </li> <li> <p><code>bar_width = 0.8</code>: <code>float</code>     Width of the bars in <code>'bar'</code> mode (between 0 and 1).</p> </li> <li> <p><code>hist_bins = 10</code>: <code>int</code>     Number of bins for the histogram.</p> </li> <li> <p><code>hist_ticklabels_format = '.2f'</code>: <code>str</code>      Format string for x-axis tick labels in histogram mode.</p> </li> <li> <p><code>hist_grouped_offset = [None, None]</code>: <code>list</code> or <code>tuple</code> of 2 elements     Offset for each group in grouped histogram mode: <code>[x_offset, y_offset]</code>.</p> </li> <li> <p><code>hist_x_log_scale = False</code>: <code>bool</code>     If True, applies log10 scale to the x-axis before plotting.</p> </li> <li> <p><code>hist_average_line = False</code>: <code>bool</code>     If True, adds a smoothed KDE (kernel density estimate) curve over the histogram.</p> </li> <li> <p><code>hist_average_line_kargs = {'linewidth':1, 'alpha':0.25, 'edgecolor':'black', 'color':'black'}</code>: <code>dict</code>     Additional keyword arguments for the KDE curve.</p> </li> <li> <p><code>external_fig_and_ax = None</code>: <code>None</code> or <code>tuple(Figure, Axes)</code>     If provided, uses the given Matplotlib <code>Figure</code> and <code>Axes</code> for plotting.</p> </li> <li> <p><code>dict_colors_of_variable_by = None</code>: <code>dict</code> or <code>None</code>     Custom color mapping for each category in the <code>by</code> column.</p> </li> <li> <p><code>verbose = None</code>: <code>bool</code>      If True, prints the min and max values of the <code>variable</code>.</p> </li> <li> <p><code>**bar_kargs</code>     Additional keyword arguments passed directly to <code>ax.bar()</code>.</p> </li> </ul> <p>Returns - <code>fig</code> (matplotlib.figure.Figure)     The created Matplotlib Figure object.</p> <ul> <li><code>ax</code> (matplotlib.axes.Axes or numpy.ndarray of Axes)     The created Axes object(s). May be an array if <code>by_mode='subploted'</code>.</li> </ul> <p>Examples</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({'Category': ['A', 'B', 'A', 'C', 'B'], 'Value': [10, 20, 30, 40, 50]})\n</code></pre> <pre><code># Basic bar plot\nplot_dist(df, variable='Category', mode='bar')\n</code></pre> <pre><code># Histogram plot with custom bins\nplot_dist(df, variable='Value', mode='hist', hist_bins=5)\n</code></pre> <pre><code># Grouped bar plot by a second variable\nplot_dist(df, variable='Category', mode='bar', by='Value', by_mode='grouped')\n</code></pre>"},{"location":"api_reference/1_eda/#plot_pairplot","title":"plot_pairplot","text":"<pre><code>function plot.plot_pairplot()\n</code></pre> <p>Create a pairplot-style scatter plot matrix with optional grouping and KDE contours.</p> <p>This function plots scatter plots for all combinations of the provided columns in a DataFrame, optionally grouped by a categorical column (<code>by</code>). It allows color and marker customization for each group and can overlay KDE contours.</p> <p>Parameters</p> <ul> <li><code>df</code> : <code>pandas.DataFrame</code>   Input dataset containing the columns to be plotted.</li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>columns = ['all']</code> : <code>list</code>     List of columns to include in the plot. If <code>['all']</code>, all numeric columns in the DataFrame are used.</p> </li> <li> <p><code>by = None</code> : <code>str</code> or <code>None</code>     Column used to group data into different categories.  </p> </li> <li> <p><code>colors_reference = ['black', '#023eff', '#ff7c00', '#1ac938', '#e8000b', '#8b2be2', '#9f4800', '#f14cc1', '#a3a3a3', '#ffc400', '#00d7ff']</code> : <code>list</code>     List of colors to use for each group in <code>by</code>.</p> </li> <li> <p><code>dict_colors_of_variable_by = None</code> : <code>dict or None</code>     Dictionary mapping each group to a specific color.</p> </li> <li> <p><code>zorder = None</code> : <code>list or None</code>     Drawing order of groups. Groups listed later appear on top.</p> </li> <li> <p><code>markers  = None</code> : <code>list or None</code>     List of marker styles for each group.</p> </li> <li> <p><code>fontsize = 10.</code> : <code>float</code>     Font size for axis labels.</p> </li> <li> <p><code>kargs_labels = {}</code> : <code>dict</code>     Additional keyword arguments for label formatting.</p> </li> <li> <p><code>figsize = (6, 6)</code> : <code>tuple</code>     Figure size in inches.</p> </li> <li> <p><code>wspace = 0.12</code> : <code>float</code>     Horizontal space between subplots.</p> </li> <li> <p><code>hspace = 0.12</code> : <code>float</code>     Vertical space between subplots.</p> </li> <li> <p><code>s = 10</code> : <code>int</code>      Marker size in the scatter plot.</p> </li> <li> <p><code>tick_majorlabel = True</code> : <code>bool</code>     Whether to show major tick labels.</p> </li> <li> <p><code>tick_labelsize = None</code> : <code>float or None</code>     Size of tick labels.</p> </li> <li> <p><code>tick_labelformat = '{x:.4g}'</code> : <code>str</code>     Format string for tick labels.</p> </li> <li> <p><code>margins = 0.08</code> : <code>float</code>     Margin added around plot limits.</p> </li> <li> <p><code>show_kdeplots = None</code> : <code>int or None</code>     If set, overlays KDE contour plots at the specified z-order.</p> </li> <li> <p><code>kdeplots_level = 3</code> : <code>int</code>     Number of contour levels in KDE plots.</p> </li> <li> <p><code>show_kdeplots_of_by = False</code> : <code>bool</code>     Whether to plot KDE contours separately for each group in <code>by</code>.</p> </li> <li> <p><code>kargs_kdeplots = {}</code> : <code>dict</code>     Additional keyword arguments passed to <code>sns.kdeplot</code>.</p> </li> <li> <p><code>**kwargs_scatter</code>     Additional keyword arguments. Passed to <code>scatter</code> for further customization.</p> </li> </ul> <p>Returns</p> <ul> <li> <p><code>fig</code> : <code>matplotlib.figure.Figure</code>   The generated figure object.</p> </li> <li> <p><code>ax</code> : <code>numpy.ndarray</code> of <code>matplotlib.axes.Axes</code>   A 2D array of Axes containing the scatter plots.</p> </li> </ul> <p>Examples</p> <pre><code>fig, ax = plot_plairplot(df, columns=['height', 'weight', 'age'], by='gender', s=20, show_kdeplots=2)\n</code></pre>"},{"location":"api_reference/4_opt/","title":"Optimization","text":"Optimization"},{"location":"api_reference/4_opt/#optuna_study","title":"optuna_study","text":"<pre><code>class opt.optuna_study()\n</code></pre> <p>An encapsulated interface for creating, loading, configuring, and running hyperparameter optimization with Optuna, including support for dynamic range adjustment, scoring strategies, and exportable checkpoints.</p> <p>This class simplifies integration of Optuna with machine learning models by allowing: - Direct instantiation of new or existing studies. - Flexible definition of hyperparameter search spaces. - Objective functions with default scoring or cross-validation scoring. - Multiple stopping criteria for early stopping or range expansion. - Automatic saving of checkpoints as <code>.pkl</code> files.</p> <p>Parameters:</p> <ul> <li> <p><code>model</code>: <code>object</code>     A scikit-learn-like estimator class (e.g., <code>RandomForestRegressor</code>) that will be optimized.</p> </li> <li> <p><code>x_train</code>: <code>pd.DataFrame</code>     The training feature dataset.</p> </li> <li> <p><code>y_train</code>: <code>pd.DataFrame</code>     The training target dataset.</p> </li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>study = 'new'</code>: <code>str</code> or <code>optuna.study.Study</code> or <code>optuna_study</code>     Defines how to initialize the Optuna study. Can be:</p> <ul> <li><code>'new'</code>: create a new study;</li> <li><code>'str</code>: A string path to a <code>.pkl</code> file containing a saved study object;</li> <li><code>optuna.study.Study</code>: An existing Optuna <code>Study</code> object.</li> </ul> </li> <li> <p><code>study_name = None</code>: <code>str</code>      Name for the study if creating a new one.</p> </li> <li> <p><code>direction = None</code>: <code>str</code>      Direction of optimization: either <code>'minimize'</code> or <code>'maximize'</code> (used if creating a new study).</p> </li> </ul> <p>Attributes:</p> <ul> <li> <p><code>model</code>: <code>type</code>     The machine learning estimator class to be tuned, e.g., <code>RandomForestRegressor</code>, <code>XGBRegressor</code>, or any scikit-learn-like model class.</p> </li> <li> <p><code>x_train</code>: <code>pd.DataFrame</code>     The training feature dataset; a pandas DataFrame containing the input features for model training.</p> </li> <li> <p><code>y_train</code>: <code>pd.DataFrame</code> or <code>pd.Series</code>       The training target dataset; a pandas DataFrame or Series containing the target variable(s).</p> </li> <li> <p><code>study</code>; <code>optuna.study.Study</code>     The <code>optuna.study.Study</code> object that manages and stores optimization trials.</p> </li> <li> <p><code>study_name</code>: <code>str</code> or <code>None</code>     Name identifier for the Optuna study. Used when creating a new study.</p> </li> <li> <p><code>direction</code>: <code>str</code>, valid values: <code>'minimize'</code> or <code>'maximize'</code>     Defines whether the optimization goal is to minimize or maximize the objective function.</p> </li> <li> <p><code>scorer</code>: <code>callable</code> or <code>dict</code>     The scoring function or a dictionary of scoring functions used to evaluate model performance during optimization.</p> </li> <li> <p><code>_objective_mode</code>: <code>str</code>, valid values: <code>'default'</code> or <code>'cv'</code>     Indicates the mode of the objective function evaluation: <code>'default'</code> for a single scorer on the training set or <code>'cv'</code> for cross-validation scoring.</p> </li> <li> <p><code>_fobj_mult</code>: <code>float</code> or <code>int</code>     A multiplier applied to the objective function score, typically used to scale the score for better numerical stability during optimization.</p> </li> <li> <p><code>_objective_mode_default</code>: <code>dict</code>     Configuration dictionary for the <code>'default'</code> mode containing keys such as <code>'scorer'</code> and <code>'scorer_locals'</code> with corresponding values.</p> </li> <li> <p><code>_objective_mode_cv</code>: <code>dict</code>     Configuration dictionary for the <code>'cv'</code> mode containing keys such as <code>'cv_scorers'</code>, <code>'cv_scorers_weight'</code>, <code>'cv'</code>, <code>'use_cv_train'</code>, and <code>'cv_train_weight'</code>.</p> </li> <li> <p><code>_hparams</code>: <code>dict</code>     Dictionary holding the hyperparameter search space and fixed model arguments, divided by types: categorical (<code>'cat'</code>), integer (<code>'int'</code>), float (<code>'float'</code>), and fixed model parameters (<code>'model'</code>).</p> </li> </ul> <p>Methods:</p> <ul> <li> <p><code>describe_study()</code>: type, valid values      Prints a summary of the current study including its name, model, number of trials, best score, dataset shape, optimization direction, and whether cross-validation is used.</p> </li> <li> <p><code>set_objective_conditions(...)</code>: type, valid values      Sets up the hyperparameter search space and the objective evaluation conditions, including scoring functions, mode (default or CV), and weights.</p> </li> <li> <p><code>_create_objective()</code>: type, valid values      Builds the objective function that Optuna will optimize, based on the set conditions. It can be called after <code>set_objective_conditions(...)</code> is called to construct a function for other applications.</p> </li> <li> <p><code>optimize(...)</code>: type, valid values      Runs the optimization process with flexible stopping criteria, supports checkpointing, and dynamic range adjustment of hyperparameters.</p> </li> </ul> <p>Examples</p> <pre><code>from sklearn.ensemble import RandomForestRegressor\nopt_study = optuna_study(\n    model=RandomForestRegressor,\n    x_train=X,\n    y_train=y,\n    direction='minimize'\n)\n</code></pre> <p>After define study:</p> <pre><code>opt_study.set_objective_conditions( ... )\n\nopt_study.optimize( ... )\n</code></pre>"},{"location":"api_reference/4_opt/#method-describe_study","title":"method: <code>describe_study()</code>","text":"<p>Prints a summary description of the current Optuna study, including the study name, model type, number of trials, best score found, dataset size, optimization direction, scoring function used, and whether cross-validation is enabled.</p>"},{"location":"api_reference/4_opt/#method-set_objective_conditions","title":"method: <code>set_objective_conditions()</code>","text":"<p>Configures the objective function to be used during optimization. Defines the hyperparameter search space and scoring strategy. Supports single scoring (<code>default</code> mode) and cross-validation scoring (<code>cv</code> mode) with multiple metrics and weighted aggregation.</p> <p>The hyperparameters must be provided as dictionaries with the format:</p> <pre><code>{parameter_name: [suggest_args, suggest_kwargs]}\n</code></pre> <p>where <code>suggest_args</code> are positional arguments for Optuna\u2019s suggest methods (e.g., ranges) and <code>suggest_kwargs</code> are optional keyword arguments (e.g., steps or logarithmic search).</p> <p>Default Parameters:</p> <ul> <li> <p><code>hparams_cat = None</code>: <code>dict</code>     Categorical hyperparameters to optimize. Format: <code>{param_name: [choices_list, {}]}</code>.</p> </li> <li> <p><code>hparams_int = None</code>: <code>dict</code>     Integer hyperparameters to optimize.     Format:</p> </li> </ul> <pre><code>    {param_name: [[low, high], {suggest_kwargs}]}\n</code></pre> <ul> <li><code>hparams_float = None</code>: <code>dict</code>     Float hyperparameters to optimize.     Format:</li> </ul> <pre><code>    {param_name: [[low, high], {suggest_kwargs}]}\n</code></pre> <ul> <li> <p><code>model_locals = None</code>: <code>dict</code>     Fixed model parameters (not optimized).</p> </li> <li> <p><code>mode = 'default'</code>: <code>str</code>     Objective evaluation mode:         - <code>'default'</code>: Uses a single scorer function on the full training set.         - <code>'cv'</code>: Uses multiple scorers combined with cross-validation.</p> </li> <li> <p><code>scorer = None</code>: <code>callable</code> or <code>str</code>     Scorer function or predefined scorer name (e.g., <code>'rmse'</code>, <code>'r2'</code>) for <code>'default'</code> mode.</p> </li> <li> <p><code>scorer_locals = {}</code>: <code>dict</code>     Keyword arguments passed to the scorer function.</p> </li> <li> <p><code>cv_scorers = None</code>: <code>str</code>, <code>callable</code>, or <code>list</code>     One or multiple scorers to use during cross-validation. Each can be a string name, a callable function <code>(y_true, y_pred)</code>, or a sklearn metrics object.</p> </li> <li> <p><code>cv_scorers_weight = None</code>: <code>float</code> or <code>list</code>     Weights for each CV scorer when aggregating results.</p> </li> <li> <p><code>cv = 5</code>: <code>int</code>      Number of folds for cross-validation.</p> </li> <li> <p><code>use_cv_train = False</code>: <code>bool</code>      If <code>True</code>, includes training scores in the CV aggregation.</p> </li> <li> <p><code>cv_train_weight = 0</code>: <code>float</code>      Weight of training scores in aggregation (range 0\u20131).</p> </li> <li> <p><code>fobj_mult = 1000</code>: <code>float</code>      Multiplier applied to the objective value to scale the score.</p> </li> </ul> <p>Examples</p> <pre><code>opt_study.set_objective_conditions(\n    hparams_float={'alpha': [[0.001, 1], {'log': True}]},\n    model_locals={'random_state': 42},\n    scorer='r2',\n    mode='default'\n)\n\nopt_study.set_objective_conditions(\n    hparams_int={'max_depth': [[3, 10], {}]},\n    cv_scorers=['r2', 'rmse'],\n    cv_scorers_weight=[0.6, 0.4],\n    mode='cv'\n)\n</code></pre> <p>For SVR model:</p> <pre><code>#hparams = { attribute_name : [ optuna_suggest_args, \n#                               optuna_suggest_kargs ] }\nhparams_float = {\n    'C': ( [1e-3, 1e3], {'step':0.001} ),\n    'gamma': ( [1e-4, 1e2], {'step':0.0001} ),\n    'epsilon': ( [0.001, 1.0], {'step':0.001} ) \n    }\n\nopt_study = optuna_study(SVR, \n                     x_train, \n                     y_train,\n                     study='new',\n                     study_name=f'SVR_with_cv',\n                     direction='maximize',\n                     )\n\nopt_study.set_objective_conditions(\n    hparams_float = hparams_float,\n    mode='cv',\n    cv_scorers='r2',\n    )\n</code></pre> <p>For RF model:</p> <pre><code>#hparams = { attribute_name : [ optuna_suggest_args, \n#                               optuna_suggest_kargs ] }\nhparams_cat = {'criterion': ['squared_error', 'absolute_error'] }\nhparams_int = {\n    'n_estimators': ( [50, 200], {'step':1} ),\n    'max_depth': ( [5, 15], {'step':1} ),\n    'min_samples_leaf': ( [1, 3], {'step':1} ),\n    'max_features': ( [1, x_train.shape[1]], {'step':1} )\n}\nhparams_float = { 'max_samples': ( [0.5, 1], {'step':0.01} ) }\nmodel_args = {'random_state': 42}\n\nopt_study = optuna_study(sklearn.ensemble.RandomForestRegressor, \n                     x_train, \n                     y_train,\n                     study='new',\n                     study_name=f'RF_with_cv',\n                     direction='minimize',\n                     )\n\nopt_study.set_objective_conditions(\n    hparams_cat = hparams_cat,\n    hparams_int = hparams_int,\n    hparams_float = hparams_float,\n    model_locals = model_args,\n    mode='cv',\n    cv_scorers='rmse',\n    cv_train_weight= 0,\n    )\n</code></pre>"},{"location":"api_reference/4_opt/#method-optimize","title":"method: <code>optimize()</code>","text":"<p>Executes the hyperparameter optimization process using the configured objective function. Supports various stopping criteria including fixed number of trials, score gradient convergence, and dynamic hyperparameter range expansion. Optionally exports checkpoints periodically as <code>.pkl</code> files.</p> <p>Parameters</p> <ul> <li><code>n_trials</code>: <code>int</code>     Number of trials to run per optimization iteration.</li> </ul> <p>Default Parameters:</p> <ul> <li> <p><code>stop_criterium = n_trials</code>: <code>str</code>     Criterion to stop optimization:         - <code>'n_trials'</code>: Stop after specified number of trials.         - <code>'best_score_gradient'</code>: Stop if score improvement falls below <code>score_gradient</code>.         - <code>'flex_range'</code>: Dynamically expand hyperparameter ranges when best values hit boundaries.</p> </li> <li> <p><code>checkpoint  = None</code>: <code>int</code>     Number of trials per checkpoint export.</p> </li> <li> <p><code>checkpoint_path = None</code>: <code>str</code>     File or directory path to save checkpoint files.</p> </li> <li> <p><code>timeout = 10</code>: <code>int</code>     Timeout in seconds per trial.</p> </li> <li> <p><code>score_gradient = None</code>: <code>float</code>     Threshold of score improvement for <code>'best_score_gradient'</code> stopping.</p> </li> <li> <p><code>min_runs_score_gradient = 3</code>: <code>int</code>     Minimum optimization iterations before applying score gradient check.</p> </li> <li> <p><code>set_flex_protocol = None</code>: <code>dict</code>     Protocol defining how to expand hyperparameter search ranges for <code>'flex_range'</code> stopping. Must be of the format:</p> </li> </ul> <pre><code>    set_flex_protocol = {\n    'param_name': (protocol_for_min_range, protocol_value) ,(protocol_for_max_range, protocol_value)\n    'param_name2': (protocol_for_min_range2, protocol_value2) ,(protocol_for_max_range2, protocol_value2)\n    ...\n    }\n</code></pre> <p>where <code>protocol_for_min_range</code> and <code>protocol_for_max_range</code> can be:</p> <ul> <li><code>'add'</code>: The <code>protocol_value</code> will adds (+) the maximum or minimum of the search range when the hyperparameter reaches it. Its <code>value</code> must be numeric;</li> <li><code>'mult'</code>: The <code>protocol_value</code> will multiply (*) the maximum or minimum of the search range when the hyperparameter reaches it. Its <code>value</code> must be numeric.</li> </ul> <p>Examples</p> <pre><code>opt_study.optimize(n_trials=100)\n\nopt_study.optimize(\n    n_trials=30,\n    stop_criterium='best_score_gradient',\n    score_gradient=0.01,\n    min_runs_score_gradient=3\n)\n\nopt_study.optimize(\n    n_trials=30,\n    stop_criterium='flex_range',\n    set_flex_protocol={\n        'alpha': [('add', 0.01), ('mult', 2)],\n        'max_depth': [('add', 1), ('add', 2)]\n    }\n)\n</code></pre> <pre><code>set_flex_protocol = {\n    #Float:\n    'C': (('mult', 0.1), ('add', 1000)),\n    'gamma': (('mult', 0.1), ('add', 100)),\n    'epsilon': (('mult', 0.1), ('add', 1)),\n}\nopt_study.optimize(\n    n_trials=3000,\n    stop_criterium='flex_range',\n    checkpoint=500,\n    checkpoint_path=f'./study/...',\n    set_flex_protocol=set_flex_protocol,\n)\n</code></pre>"}]}